{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs = pd.read_csv('../data/blog-gender-dataset_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='char', binary=True, ngram_range=(2, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_fit = cv.fit_transform(blogs.Blog.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/feature_dumps/both_binary_and_scaled.pkl', 'rb') as pkldump:\n",
    "    features = load(pkldump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = hstack((features, char_fit), format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3212, 52542)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3212, 3264525)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/feature_dumps/both_binary_and_scaled_with_char_ngrams.pkl', 'wb') as pkldump:\n",
    "    dump(new_features, pkldump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/feature_dumps/both_binary_and_scaled_with_char_ngrams.pkl', 'rb') as pkldump:\n",
    "    new_features = load(pkldump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import GenericUnivariateSelect, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GenericUnivariateSelect(chi2, 'k_best', param=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = selector.fit_transform(new_features, blogs.Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/feature_dumps/both_binary_and_scaled_with_char_ngrams_50k_best.pkl', 'wb') as pkldump:\n",
    "    dump(selected_features, pkldump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3212, 50000)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(95, 95), activation='identity', early_stopping=True, solver='adam', \n",
    "                    max_iter=2500, learning_rate='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(mlp, selected_features, blogs.Gender, cv=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  [0.86996904 0.92211838 0.84423676 0.81931464 0.894081   0.79127726\n",
      " 0.82242991 0.87227414 0.86915888 0.82242991]\n",
      "Average score =  0.8527289912521822\n"
     ]
    }
   ],
   "source": [
    "print(\"Score = \", score)\n",
    "print(\"Average score = \", np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump as jdump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/mlp_v4_2']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdump(mlp, '../models/mlp_v4_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_layers = list(range(75, 105, 10))\n",
    "n_units = list(range(75, 105, 10))\n",
    "depth = list(product(n_layers, n_units))\n",
    "activations = ['relu', 'logistic', 'tanh', 'identity']\n",
    "solvers = ['adam']\n",
    "learning_rates = ['constant']\n",
    "max_iters = [400, 1000, 1600, 2000]\n",
    "early_stopping = [True]\n",
    "params_grid = {\n",
    "    'hidden_layer_sizes': depth,\n",
    "    'activation': activations,\n",
    "    'solver': solvers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'max_iter': max_iters,\n",
    "    'early_stopping': early_stopping\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/home/binoy/.local/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 60.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 159.0min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 296.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 467.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 677.1min finished\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(MLPClassifier(), params_grid, cv=10, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_result = grid_search.fit(selected_features, blogs.Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'identity', 'early_stopping': True, 'hidden_layer_sizes': (95, 95), 'learning_rate': 'constant', 'max_iter': 2000, 'solver': 'adam'}\n",
      "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(95, 95), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "0.8642590286425903\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_params_)\n",
    "print(grid_result.best_estimator_)\n",
    "print(grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "btr, bte, gtr, gte = train_test_split(selected_features, blogs.Gender, test_size=0.1, stratify=blogs.Gender, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(95, 95), activation='identity', early_stopping=True, solver='adam', \n",
    "                    max_iter=2500, learning_rate='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  [0.9        0.88965517 0.85517241 0.85467128 0.86851211 0.82352941\n",
      " 0.87889273 0.88888889 0.85416667 0.83333333]\n",
      "Average score =  0.8646822011427966\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(mlp, btr, gtr, cv=10, n_jobs=1)\n",
    "print(\"Score = \", score)\n",
    "print(\"Average score = \", np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(95, 95), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=2500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(btr, gtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(bte, gte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/mlp_v4_3']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdump(mlp, '../models/mlp_v4_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = mlp.score(bte, gte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(bte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,  27],\n",
       "       [ 19, 149]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(gte, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision =  0.8465909090909091\n",
      "Female precision =  0.8698630136986302\n"
     ]
    }
   ],
   "source": [
    "print(\"Male precision = \", precision_score(gte, predictions, pos_label='M'))\n",
    "print(\"Female precision = \", precision_score(gte, predictions, pos_label='F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male recall =  0.8869047619047619\n",
      "Female recall =  0.8246753246753247\n"
     ]
    }
   ],
   "source": [
    "print(\"Male recall = \", recall_score(gte, predictions, pos_label='M'))\n",
    "print(\"Female recall = \", recall_score(gte, predictions, pos_label='F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male F1 =  0.8662790697674417\n",
      "Female F1 =  0.8466666666666668\n"
     ]
    }
   ],
   "source": [
    "print(\"Male F1 = \", f1_score(gte, predictions, pos_label='M'))\n",
    "print(\"Female F1 = \", f1_score(gte, predictions, pos_label='F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Precision 0.8571428571428571\n",
      "Global Recall 0.8571428571428571\n",
      "Global F1 =  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Global Precision\", precision_score(gte, predictions, average='micro'))\n",
    "print(\"Global Recall\", recall_score(gte, predictions, average='micro'))\n",
    "print(\"Global F1 = \", f1_score(gte, predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "btr2, bv, gtr2, gv = train_test_split(btr, gtr, test_size=0.18, stratify=gtr, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(75, 75), activation='identity', early_stopping=True, solver='adam', \n",
    "                    max_iter=2500, learning_rate='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(75, 75), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=2500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(btr2, gtr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8733205374280231"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(bv, gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8726708074534162"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(bte, gte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/mlp_v6']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdump(mlp, '../models/mlp_v6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  [0.89655172 0.86206897 0.87586207 0.89965398 0.8650519  0.85467128\n",
      " 0.87543253 0.90972222 0.86805556 0.89583333]\n",
      "Average score =  0.8802903558313115\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(mlp, btr, gtr, cv=10, n_jobs=1)\n",
    "print(\"Score = \", score)\n",
    "print(\"Average score = \", np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
