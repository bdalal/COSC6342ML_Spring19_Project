{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle('../data/feature_dumps/features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/POS_Tags.pkl', 'rb') as pkldump:\n",
    "    pos_tags = load(pkldump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = list(map(lambda tags: ' '.join(tags), pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert POS, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-18a94883152a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3471\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3472\u001b[0m         self._data.insert(loc, column, value,\n\u001b[0;32m-> 3473\u001b[0;31m                           allow_duplicates=allow_duplicates)\n\u001b[0m\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot insert {}, already exists'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert POS, already exists"
     ]
    }
   ],
   "source": [
    "features.insert(2, 'POS', pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(features, '../data/feature_dumps/features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_set = {'NN', 'NNS', 'NNP', 'NNPS'}\n",
    "adjective_set = {'JJ', 'JJR', 'JJS', 'WDT'}\n",
    "preposition_set = {'IN'}\n",
    "article_set = {'DET', 'DT'}\n",
    "pronoun_set = {'PRP', 'PRP$', 'WP', 'WP$'}\n",
    "adverb_set = {'RB', 'RBR', 'RBS', 'EX'}\n",
    "interjection_set = {'UH'}\n",
    "verb_set = {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'MD'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = []\n",
    "for tags in features.POS.values:\n",
    "    fnoun = fadj = fprep = fart = fpron = fverb = fadv = fint = 0\n",
    "    for tag in tags.split():\n",
    "        if tag in noun_set:\n",
    "            fnoun += 1\n",
    "        elif tag in adjective_set:\n",
    "            fadj += 1\n",
    "        elif tag in preposition_set:\n",
    "            fprep += 1\n",
    "        elif tag in article_set:\n",
    "            fart += 1\n",
    "        elif tag in pronoun_set:\n",
    "            fpron += 1\n",
    "        elif tag in adverb_set:\n",
    "            fadv += 1\n",
    "        elif tag in interjection_set:\n",
    "            fint += 1\n",
    "        elif tag in verb_set:\n",
    "            fverb += 1\n",
    "    f_measure = 0.5 * ((fnoun + fadj + fprep + fart) - (fpron + fverb + fadv + fint) + 100)\n",
    "    fm.append(f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['FMeasure'] = fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(features, '../data/feature_dumps/features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blog', 'Gender', 'POS', 'FMeasure', 'CharLength', 'TFPunctuation',\n",
       "       'TFStopWords', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8',\n",
       "       'f9', 'f10', 'f11', 'ConversationCount', 'AtHomeCount',\n",
       "       'FamilyCount', 'TimeCount', 'WorkCount', 'PastActionsCount',\n",
       "       'GamesCount', 'InternetCount', 'LocationCount', 'FunCount',\n",
       "       'Food/ClothesCount', 'PoeticCount', 'Books/MoviesCount',\n",
       "       'ReligionCount', 'RomanceCount', 'SwearingCount', 'PoliticsCount',\n",
       "       'MusicCount', 'SchoolCount', 'BusinessCount', 'PositiveCount',\n",
       "       'NegativeCount', 'EmotionCount', 'ProperNounCount',\n",
       "       'SentenceCount', 'AvgSentLength', 'NN', 'NNPS', 'VBD', 'VBZ', 'MD',\n",
       "       'EX', 'IN', 'VB', 'JJR', 'JJS', 'PRP', 'WDT', 'JJ', 'VBP', 'NNS',\n",
       "       'VBN', 'DT', 'RB', 'WP', 'VBG', 'NNP', 'RBR', 'PRP$', 'JJ NN',\n",
       "       'VBP VB', 'VBD PRP', 'IN IN', 'NNP VBZ', 'RB DT', 'NN VBG',\n",
       "       'IN JJ', 'NN NN', 'RB VBZ', 'VBG DT', 'NN NNS', 'VBZ JJ', 'IN RB',\n",
       "       'JJ JJ', 'NN VBZ', 'IN VBG', 'VBP DT', 'VB NN', 'NNS VBP',\n",
       "       'DT NNP', 'PRP VBZ', 'PRP VBD', 'PRP VB', 'NN PRP', 'NN DT',\n",
       "       'VBZ VB', 'PRP VBP', 'PRP$ JJ', 'VBD IN', 'VB JJ', 'NN JJ',\n",
       "       'RB VB', 'JJ NNP', 'RB VBG', 'VBZ PRP', 'VBD DT', 'RB RB', 'JJ VB',\n",
       "       'PRP RB', 'JJ IN', 'VBD VB', 'VB IN', 'VBP PRP', 'VBD RB',\n",
       "       'VBG IN', 'PRP IN', 'VB PRP', 'NN RB', 'NNP NN', 'VB VBN',\n",
       "       'NN NNP', 'IN NN', 'VBP VBN', 'NN WDT', 'RB IN', 'DT JJ', 'RB VBD',\n",
       "       'VBZ IN', 'NN MD', 'VB DT', 'NNS IN', 'NNP RB', 'VB PRP$',\n",
       "       'VBP IN', 'RB VBP', 'NNS RB', 'DT NN', 'VBZ VBN', 'MD RB',\n",
       "       'NNP IN', 'NN VBD', 'JJ NNS', 'NN VB', 'IN PRP$', 'MD VB',\n",
       "       'RB PRP', 'NNS VB', 'VBZ DT', 'VBG NN', 'VBN IN', 'PRP$ NNS',\n",
       "       'VB VB', 'VBP RB', 'NNP NNP', 'NN IN', 'VB RB', 'VBG PRP',\n",
       "       'PRP MD', 'IN DT', 'NNP VBD', 'IN NNS', 'IN NNP', 'RB JJ',\n",
       "       'IN PRP', 'VBD JJ', 'RB VBN', 'DT NNS', 'VBD VBN', 'PRP$ NN',\n",
       "       'VBZ RB', 'VBP JJ', 'DT NN VBZ', 'PRP VBD IN', 'JJ NNP NN',\n",
       "       'DT NNP NNP', 'RB IN PRP', 'IN JJ NN', 'JJ NN VB', 'IN NN IN',\n",
       "       'IN DT NNS', 'NNS IN PRP', 'NN IN NNS', 'VBN IN DT', 'PRP VBP JJ',\n",
       "       'DT NNP NN', 'VBZ DT NN', 'PRP VBP RB', 'IN DT JJ', 'MD RB VB',\n",
       "       'JJ NN IN', 'RB DT NN', 'VBG DT NN', 'NNP NN NN', 'DT NNS IN',\n",
       "       'DT NN IN', 'JJ NN NN', 'VB DT NN', 'DT JJ NNS', 'NN IN PRP$',\n",
       "       'IN JJ NNS', 'NNS IN NN', 'VBZ DT JJ', 'PRP VBP DT', 'NNP NNP NN',\n",
       "       'PRP VBP PRP', 'VB DT JJ', 'VB PRP$ NN', 'DT JJ JJ', 'IN PRP VBP',\n",
       "       'DT NN VB', 'IN NNP NNP', 'NNS IN DT', 'VB IN DT', 'IN DT NNP',\n",
       "       'NN IN NNP', 'IN PRP$ NN', 'DT JJ NN', 'NN NN IN', 'IN NN NN',\n",
       "       'VBP DT NN', 'PRP MD VB', 'PRP$ NN NN', 'RB JJ NN', 'DT NN NN',\n",
       "       'IN PRP$ JJ', 'VBD DT JJ', 'PRP VBP VB', 'NN NN NN', 'VBD DT NN',\n",
       "       'NNP NNP NNP', 'PRP VBD VB', 'JJ NNS IN', 'IN DT NN', 'NN IN NN',\n",
       "       'PRP VBP IN', 'PRP VBD DT', 'IN PRP VBD', 'NN IN JJ', 'DT NN RB',\n",
       "       'NN IN PRP', 'NN IN DT', 'RB IN DT', 'JJ JJ NN', 'PRP$ NN IN',\n",
       "       'RB PRP VBP', 'PRP$ JJ NN', 'IN DT JJ NN', 'NN IN DT NN',\n",
       "       'NN IN PRP$ NN', 'NN IN DT JJ', 'IN DT NN VB', 'DT JJ NN IN',\n",
       "       'IN DT NN NN', 'DT JJ NN NN', 'VB DT JJ NN', 'IN DT NNP NN',\n",
       "       'DT NN IN PRP', 'JJ NN IN DT', 'DT NN IN NN', 'NNS IN DT NN',\n",
       "       'VB DT NN IN', 'NN IN JJ NN', 'DT NN IN DT', 'JJ NN IN NN',\n",
       "       'IN DT NN IN', 'DT NN IN DT NN', 'NN IN DT JJ NN',\n",
       "       'DT JJ NN IN NN', 'JJ NN IN DT NN', 'UpperCaseChars',\n",
       "       'UpperCaseWords', 'TitleCaseWords', 'DT VBZ', 'DT RB', 'VBD NN',\n",
       "       'NNP VB', 'IN NNP NN', 'JJ NNS VB', 'PRP$ NN VB', 'VBN IN NN',\n",
       "       'NN NN VB', 'PRP RB VB', 'VBZ NN', 'DT IN', 'DT VB', 'RB NN',\n",
       "       'WP VB', 'VBP NN', 'DT DT', 'VBN NN', 'IN VB', 'WDT VB',\n",
       "       'IN PRP VB', 'NNP NNP VB', 'NN IN VB', 'RB PRP VB', 'NN PRP VB'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.69269898264513"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[features.Gender == 'M'].FMeasure.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.00778715120052"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[features.Gender == 'F'].FMeasure.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = ['CharLength', 'TFPunctuation',\n",
    "       'TFStopWords', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8',\n",
    "       'f9', 'f10', 'f11', 'ConversationCount', 'AtHomeCount',\n",
    "       'FamilyCount', 'TimeCount', 'WorkCount', 'PastActionsCount',\n",
    "       'GamesCount', 'InternetCount', 'LocationCount', 'FunCount',\n",
    "       'Food/ClothesCount', 'PoeticCount', 'Books/MoviesCount',\n",
    "       'ReligionCount', 'RomanceCount', 'SwearingCount', 'PoliticsCount',\n",
    "       'MusicCount', 'SchoolCount', 'BusinessCount', 'PositiveCount',\n",
    "       'NegativeCount', 'EmotionCount', 'ProperNounCount',\n",
    "       'SentenceCount', 'AvgSentLength', 'UpperCaseChars',\n",
    "       'UpperCaseWords', 'TitleCaseWords', 'FMeasure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binoy/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scaled_features = scaler.fit_transform(features[['CharLength', 'TFPunctuation',\n",
    "       'TFStopWords', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8',\n",
    "       'f9', 'f10', 'f11', 'ConversationCount', 'AtHomeCount',\n",
    "       'FamilyCount', 'TimeCount', 'WorkCount', 'PastActionsCount',\n",
    "       'GamesCount', 'InternetCount', 'LocationCount', 'FunCount',\n",
    "       'Food/ClothesCount', 'PoeticCount', 'Books/MoviesCount',\n",
    "       'ReligionCount', 'RomanceCount', 'SwearingCount', 'PoliticsCount',\n",
    "       'MusicCount', 'SchoolCount', 'BusinessCount', 'PositiveCount',\n",
    "       'NegativeCount', 'EmotionCount', 'ProperNounCount',\n",
    "       'SentenceCount', 'AvgSentLength', 'UpperCaseChars',\n",
    "       'UpperCaseWords', 'TitleCaseWords', 'FMeasure']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[['CharLength', 'TFPunctuation',\n",
    "       'TFStopWords', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8',\n",
    "       'f9', 'f10', 'f11', 'ConversationCount', 'AtHomeCount',\n",
    "       'FamilyCount', 'TimeCount', 'WorkCount', 'PastActionsCount',\n",
    "       'GamesCount', 'InternetCount', 'LocationCount', 'FunCount',\n",
    "       'Food/ClothesCount', 'PoeticCount', 'Books/MoviesCount',\n",
    "       'ReligionCount', 'RomanceCount', 'SwearingCount', 'PoliticsCount',\n",
    "       'MusicCount', 'SchoolCount', 'BusinessCount', 'PositiveCount',\n",
    "       'NegativeCount', 'EmotionCount', 'ProperNounCount',\n",
    "       'SentenceCount', 'AvgSentLength', 'UpperCaseChars',\n",
    "       'UpperCaseWords', 'TitleCaseWords', 'FMeasure']] = scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means for  CharLength\n",
      "Male =  0.07346503932184074 Female =  0.0689864719147496\n",
      "\n",
      "Means for  TFPunctuation\n",
      "Male =  0.04771450239140285 Female =  0.04805362792636811\n",
      "\n",
      "Means for  TFStopWords\n",
      "Male =  0.06028191885751045 Female =  0.058479253226439556\n",
      "\n",
      "Means for  f1\n",
      "Male =  0.016130154621240587 Female =  0.01260130087680908\n",
      "\n",
      "Means for  f2\n",
      "Male =  0.026290107259586613 Female =  0.018289821794039835\n",
      "\n",
      "Means for  f3\n",
      "Male =  0.02492091989398991 Female =  0.03198294243070362\n",
      "\n",
      "Means for  f4\n",
      "Male =  0.014961101137043686 Female =  0.01058565866320571\n",
      "\n",
      "Means for  f5\n",
      "Male =  0.030864751645721125 Female =  0.02310188189487346\n",
      "\n",
      "Means for  f6\n",
      "Male =  0.037159634949132256 Female =  0.031108046722907203\n",
      "\n",
      "Means for  f7\n",
      "Male =  0.030847070344377347 Female =  0.022948498613651114\n",
      "\n",
      "Means for  f8\n",
      "Male =  0.03920436236414693 Female =  0.039185344182099534\n",
      "\n",
      "Means for  f9\n",
      "Male =  0.011316032860018498 Female =  0.011090791103769688\n",
      "\n",
      "Means for  f10\n",
      "Male =  0.01286654697785757 Female =  0.016872160934458143\n",
      "\n",
      "Means for  f11\n",
      "Male =  0.005745062836624777 Female =  0.005191434133679429\n",
      "\n",
      "Means for  ConversationCount\n",
      "Male =  0.036358298612287294 Female =  0.03954183144980593\n",
      "\n",
      "Means for  AtHomeCount\n",
      "Male =  0.030000944911650763 Female =  0.041736398101028034\n",
      "\n",
      "Means for  FamilyCount\n",
      "Male =  0.026786052466119738 Female =  0.032692892170955896\n",
      "\n",
      "Means for  TimeCount\n",
      "Male =  0.02150223372719302 Female =  0.029820563512065558\n",
      "\n",
      "Means for  WorkCount\n",
      "Male =  0.02220011103660603 Female =  0.023549095799160303\n",
      "\n",
      "Means for  PastActionsCount\n",
      "Male =  0.020717872661514845 Female =  0.02606297435318681\n",
      "\n",
      "Means for  GamesCount\n",
      "Male =  0.020075496018045386 Female =  0.015334697748714621\n",
      "\n",
      "Means for  InternetCount\n",
      "Male =  0.030842885420982364 Female =  0.024579443917536067\n",
      "\n",
      "Means for  LocationCount\n",
      "Male =  0.02191599139534508 Female =  0.025448550432327202\n",
      "\n",
      "Means for  FunCount\n",
      "Male =  0.02087649035584404 Female =  0.02750461738132082\n",
      "\n",
      "Means for  Food/ClothesCount\n",
      "Male =  0.017934907701514523 Female =  0.026765836369989516\n",
      "\n",
      "Means for  PoeticCount\n",
      "Male =  0.02289048473967684 Female =  0.027891479059551746\n",
      "\n",
      "Means for  Books/MoviesCount\n",
      "Male =  0.014353232775885058 Female =  0.013872779205649262\n",
      "\n",
      "Means for  ReligionCount\n",
      "Male =  0.022797330713729212 Female =  0.022161546655565488\n",
      "\n",
      "Means for  RomanceCount\n",
      "Male =  0.02750912144553194 Female =  0.040547612568294575\n",
      "\n",
      "Means for  SwearingCount\n",
      "Male =  0.01891603569848828 Female =  0.016759303670682502\n",
      "\n",
      "Means for  PoliticsCount\n",
      "Male =  0.018934377176717584 Female =  0.011691364985478878\n",
      "\n",
      "Means for  MusicCount\n",
      "Male =  0.020848120468178088 Female =  0.01942260386641112\n",
      "\n",
      "Means for  SchoolCount\n",
      "Male =  0.019892280071813286 Female =  0.022634652822842313\n",
      "\n",
      "Means for  BusinessCount\n",
      "Male =  0.02609216038300419 Female =  0.014977287475665152\n",
      "\n",
      "Means for  PositiveCount\n",
      "Male =  0.036849192100538594 Female =  0.04076898118105127\n",
      "\n",
      "Means for  NegativeCount\n",
      "Male =  0.020700723573254993 Female =  0.020028316913456433\n",
      "\n",
      "Means for  EmotionCount\n",
      "Male =  0.018694252087429822 Female =  0.02295973548407033\n",
      "\n",
      "Means for  ProperNounCount\n",
      "Male =  0.030453652959105723 Female =  0.024651023782209392\n",
      "\n",
      "Means for  SentenceCount\n",
      "Male =  0.03795698195002272 Female =  0.04038859936088272\n",
      "\n",
      "Means for  AvgSentLength\n",
      "Male =  0.09967084367791412 Female =  0.08476178963920776\n",
      "\n",
      "Means for  UpperCaseChars\n",
      "Male =  0.03241222252467861 Female =  0.029127881152102533\n",
      "\n",
      "Means for  UpperCaseWords\n",
      "Male =  0.032243080172853704 Female =  0.03990087743325497\n",
      "\n",
      "Means for  TitleCaseWords\n",
      "Male =  0.02789792468600428 Female =  0.025496214127691395\n",
      "\n",
      "Means for  FMeasure\n",
      "Male =  0.09653737208836528 Female =  0.08296688666222082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in n_features:\n",
    "    print(\"Means for \", feature)\n",
    "    print(\"Male = \", features[features.Gender == 'M'][feature].values.mean(), \n",
    "         \"Female = \", features[features.Gender == 'F'][feature].values.mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import fabs\n",
    "for feature in n_features:\n",
    "    mm = features[features.Gender == 'M'][feature].values.mean() \n",
    "    fm = features[features.Gender == 'F'][feature].values.mean()\n",
    "    if 0.05 < fabs(mm - fm) < 0.08:\n",
    "        print(feature, fabs(mm - fm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(features, '../data/feature_dumps/scaled_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
